{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start..\n",
      "*soup3=> <html>\n",
      "<head>\n",
      "<title>My Little Network Science Lab</title>\n",
      "<link href=\"style.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
      "<meta charset=\"utf-8\"/>\n",
      "</head>\n",
      "<body>\n",
      "<h1>My Little Network Science Lab</h1>\n",
      "<h2>By Dmitry Zinoviev</h2>\n",
      "<p>\n",
      "</p><table class=\"hdr\"><tr><td><h3 class=\"nomargin\">Books</h3></td></tr></table>\n",
      "<p>\n",
      "<a href=\"https://pragprog.com/book/dzpyds/data-science-essentials-in-python\"><img align=\"left\" border=\"1\" src=\"https://imagery.pragprog.com/products/490/dzpyds_xlargecover.jpg?1468006361\"/></a>\n",
      "<a href=\"https://pragprog.com/book/dzcnapy/complex-network-analysis-in-python\"><img align=\"left\" border=\"1\" src=\"https://imagery.pragprog.com/products/541/dzcnapy_xlargecover.jpg?1508250011\"/></a>\n",
      "\n",
      "\n",
      "I am excited to announce my books, \"Data Science Essentials in Python. Collect →  Organize →  Explore →  Predict →  Value\" (a.k.a. DZPYDS) and \"Complex Network Analysis in Python. Recognize → Construct → Visualize → Analyze → Interpret\" (a.k.a. DZCNAPY), published by the Pragmatic Bookshelf.\n",
      "</p><p>\n",
      "The <b>first book</b> is intended for seasoned data scientists and statisticians migrating from R to Python, as well as for beginners willing to learn elements of data science in Python.\n",
      "</p><p>\n",
      "The book leads you from messy, unstructured artifacts stored in SQL and NoSQL databases to a neat, well-organized dataset. It covers text mining, machine learning, and network analysis; processing numeric data with the NumPy and Pandas modules; and describing and analyzing data using statistical and network-theoretical methods. It has actual examples of data analysis at work, as well as mini-projects for you to enjoy. \n",
      "</p><p>\n",
      "  The <b>second book</b> shows how, starting with simple networks, one can convert real-life and synthetic network graphs into Networkx data structures. The reader will look at more sophisticated networks and learn more powerful machinery to handle centrality calculation, blockmodeling, and clique and community detection. Get familiar with presentation-quality network visualization tools, both programmable and interactive--such as Gephi, a CNA explorer. The reader will  adapt the patterns from the case studies to your problems, explore big networks with NetworKit, a high-performance networkx substitute. Each part in the book gives an overview of a class of networks, includes a practical study of networkx functions and techniques, and concludes with case studies from various fields, including social networking, anthropology, marketing, and sports analytics.\n",
      "</p><p>\n",
      "  \n",
      "The books are available for purchase at the publisher's site, and on Amazon (<a href=\"https://www.amazon.com/gp/product/1680501844\">DZPYDS</a>, <a href=\"https://www.amazon.com/gp/product/1680502697\">DZCNAPY</a>).\n",
      "</p><p>\n",
      "</p><table class=\"hdr\"><tr><td><h3 class=\"nomargin\">Presentations</h3></td></tr></table>\n",
      "<ul>\n",
      "<li><a href=\"http://www.slideshare.net/DmitryZinoviev/networks-of-music-groups-as-success-predictors\">Networks of Music Groups as Success Predictors</a> - Social networks, digital humanities\n",
      "</li><li><a href=\"http://www.slideshare.net/DmitryZinoviev/workshop-20212296\">Network Science Workshop</a> - General networks\n",
      "</li><li><a href=\"http://www.slideshare.net/DmitryZinoviev/resilience-in-transactional-networks\">Resilience in Transaction-Oriented Networks</a> - Communication networks\n",
      "</li><li><a href=\"http://www.slideshare.net/DmitryZinoviev/peer-ratings-in-massive-online-social-networks\">Peer Ratings in Massive Online Social Networks</a> - Social networks\n",
      "</li><li><a href=\"http://www.slideshare.net/DmitryZinoviev/presentation-31680572\">Semantic Networks of Interests in Online NSSI Communities</a> - Semantic networks\n",
      "</li><li><a href=\"http://www.slideshare.net/DmitryZinoviev/10-monthsymposiumbeta\">Towards an Ideal Store</a> - Product networks\n",
      "</li></ul>\n",
      "<table class=\"hdr\"><tr><td><h3 class=\"nomargin\">Publications</h3></td></tr></table>\n",
      "<ul>\n",
      "<li><a href=\"https://media.pragprog.com/newsletters/2016-04-06.html\">D.Zinoviev, \"Analyzing Cultural Domains with Python,\"</a> <i>PragPub</i>, 82, pp. 26-33, Apr 2016\n",
      "</li><li><a href=\"http://dhj.sagepub.com/content/2/2055207616642118.full\">D. Zinoviev, D. Stefanescu, G. Fireman, and L. Swenson, \"Semantic networks of interests in online non-suicidal self-injury communities,\"</a> <i>Digital Health</i>, doi:10.1177/2055207616642118, SAGE, Apr 2016\n",
      "</li><li><a href=\"http://www.mitpressjournals.org/doi/abs/10.1162/LEON_a_01271#.VzOvwHUrKzc\">D.Zinoviev, \"The Pain of Complexity,\"</a>, <i>Leonardo</i>, 2016\n",
      "</li><li><a href=\"http://link.springer.com/chapter/10.1007/978-3-319-16112-9_18\">D.Zinoviev, Z.Zhu, and K.Li, \"Building mini-categories in product networks,\"</a> in <i>Studies in Computational Intelligence</i>, vol. 597, pp. 179-190, Springer, Mar 2015\n",
      "</li><li><a href=\"http://arxiv.org/abs/1409.6771\">D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Mitigation of delayed management costs in transaction-oriented systems,\"</a> Sep 2014\n",
      "</li><li><a href=\"http://dl.acm.org/citation.cfm?id=2499974\">D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Simulating resilience in transaction-oriented networks,\"</a> in <i>Proc. Spring Simulation Multi-Conference</i>, (San Diego, CA), Apr. 2013\n",
      "</li><li><a href=\"http://arxiv.org/abs/1206.5520\">D.Zinoviev, D.Stefanescu, L.Swenson, and G.Fireman, \"Semantic networks of interests in online NSSI communities,\"</a> in <i>Proc. Workshop \"Words and Networks\"</i> (Evanston, IL), June 2012\n",
      "</li><li><a href=\"http://arxiv.org/abs/1401.6964\">D.Zinoviev and S.Llewelyn, \"Co-Evolution of Friendship and Publishing in Online Blogging Social Networks,\"</a> <i>WebSci-2012</i> (poster)\n",
      "</li><li><a href=\"http://dl.acm.org/citation.cfm?id=2208181\">D.Zinoviev, \"Information diffusion in social networks,\"</a> in <i>Social Networking and Community Behavior Modeling: Qualitative and Quantitative Measures</i> (M. Safar, ed.), Hershey, PA: IGI Global, Dec. 2011\n",
      "</li><li><a href=\"http://dl.acm.org/citation.cfm?id=2048377\">D.Zinoviev and V.Duong, \"A game theoretical approach to broadcast  information diffusion in social networks,\"</a> 6. in <i>Proc. 44th Annual Simulation Symp.</i>, (Boston, MA), pp. 47-52, Apr. 2011\n",
      "</li><li><a href=\"http://dl.acm.org/citation.cfm?id=1999462\">D.Zinoviev and V.Duong, \"A game theoretical approach to modeling full-duplex information dissemination,\"</a> in <i>Proc. Summer Simulation Multi-Conference</i>, (Ottawa, Canada), pp. 358-363, July 2010\n",
      "</li><li><a href=\"http://arxiv.org/abs/1006.5493\">D.Zinoviev, V.Duong, and H.Zhang, \"A game theoretical approach to modeling information dissemination in social networks,\"</a> in <i>Proc. Int. Multi-Conference on Complexity, Informatics and Cybernetics</i>, vol. I, pp. 407-412, IIIS, Apr. 2010\n",
      "</li><li><a href=\"http://arxiv.org/abs/0902.4658\">D.Zinoviev and V.Duong, \"Toward Understanding Friendship in Online Social Networks,\"</a> <i>The Intl J. of Technology, Knowledge, and Society</i>, pp. 1-8, May 2009\n",
      "</li><li><a href=\"http://arxiv.org/abs/0807.3996\">D.Zinoviev, \"Topology and Geometry of Online Social Networks,\"</a> in <i>Proc. 12th World Multi-Conference on Systemics, Cybernetics and Informatics</i>, vol. VI, pp. 138-143, 2008\n",
      "</li></ul>\n",
      "<table class=\"hdr\"><tr><td><h3 class=\"nomargin\">Other Projects</h3></td></tr></table>\n",
      "<ul>\n",
      "<li><a href=\"/vixi/html5/\">Vixi: The Game of Meaning</a>, produced in collaboration with <a href=\"http://meaningoflife.cherkasova.org/\">Evgenia Cherkasova</a> from Philosophy Department.\n",
      "</li><li><a href=\"v2.jpg\">All Characters from War and Peace by L.Tolstoy</a>\n",
      "</li><li><a href=\"bible-networks.pdf\">Mapping the Bible: Social Networks in the Holy Book</a>. A book of graphs.\n",
      "</li><li><a href=\"wc2014.gif\">FIFA World Cup 2014: Who Beat Whom?</a>\n",
      "</li><li><a href=\"facebook_spread.gif\">The seed post \"9 American habits I lost when I moved to Germany\" and its 125 \"likes\" and \"shares\" on Facebook</a>. Nodes represent Facebook users, node sizes - number of friends/followers. Two nodes are connected if they are friends/followers and both reacted to the seed post. Red nodes denote shares. The post was originally published at the yellow node.\n",
      "</li></ul>\n",
      "<table class=\"hdr\"><tr><td><h3 class=\"nomargin\">Contacts</h3></td></tr></table>\n",
      "<ul>\n",
      "<li><a href=\"mailto:dzinoviev@suffolk.edu\">Email</a>\n",
      "</li><li><a href=\"https://www.suffolk.edu/academics/faculty/z/i/dmitry-zinoviev\">Suffolk University</a>\n",
      "</li><li><a href=\"https://scholar.google.com/citations?hl=en&amp;user=j5GjuIkAAAAJ&amp;sortby=pubdate&amp;view_op=list_works&amp;pagesize=100\">Google Scholar</a>\n",
      "</li><li><a href=\"https://www.linkedin.com/pub/dmitry-zinoviev/4/a78/27b\">LinkedIn</a>\n",
      "</li><li><a href=\"https://suffolk.academia.edu/DmitryZinoviev\">Academia.edu</a>\n",
      "</li><li><a href=\"https://www.researchgate.net/profile/Dmitry_Zinoviev\">ResearchGate</a>\n",
      "</li></ul>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3장\n",
    "print('start..')\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "# 문자열에서 soup을 생성한다.\n",
    "soup1 = BeautifulSoup(\"<HTML><HEAD><header></HEAD><body></HTML>\")\n",
    "# 로컬 파일에서 soup을 생성한다. 내려받은 myDoc.html 파일을 사용한다.\n",
    "soup2 = BeautifulSoup(open(\"myDoc.html\"))\n",
    "# 웹 문서에서 soup을 생성한다.\n",
    "# urlopen()이 “http://“를 자동으로 추가해주지 않는다는 것을 기억하자!\n",
    "soup3 = BeautifulSoup(urlopen(\"http://www.networksciencelab.com/\"))\n",
    "print('*soup3=>', soup3)\n",
    "#---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*soup=> <html>\n",
      "<head><title>My document</title></head>\n",
      "<body>Main text.</body></html>\n",
      "\n",
      "*mystr=> \n",
      "My document\n",
      "Main text.\n",
      "\n",
      "*links=> links=> [(None, 'https://pragprog.com/book/dzpyds/data-science-essentials-in-python'), (None, 'https://pragprog.com/book/dzcnapy/complex-network-analysis-in-python'), ('DZPYDS', 'https://www.amazon.com/gp/product/1680501844'), ('DZCNAPY', 'https://www.amazon.com/gp/product/1680502697'), ('Networks of Music Groups as Success Predictors', 'http://www.slideshare.net/DmitryZinoviev/networks-of-music-groups-as-success-predictors'), ('Network Science Workshop', 'http://www.slideshare.net/DmitryZinoviev/workshop-20212296'), ('Resilience in Transaction-Oriented Networks', 'http://www.slideshare.net/DmitryZinoviev/resilience-in-transactional-networks'), ('Peer Ratings in Massive Online Social Networks', 'http://www.slideshare.net/DmitryZinoviev/peer-ratings-in-massive-online-social-networks'), ('Semantic Networks of Interests in Online NSSI Communities', 'http://www.slideshare.net/DmitryZinoviev/presentation-31680572'), ('Towards an Ideal Store', 'http://www.slideshare.net/DmitryZinoviev/10-monthsymposiumbeta'), ('D.Zinoviev, \"Analyzing Cultural Domains with Python,\"', 'https://media.pragprog.com/newsletters/2016-04-06.html'), ('D. Zinoviev, D. Stefanescu, G. Fireman, and L. Swenson, \"Semantic networks of interests in online non-suicidal self-injury communities,\"', 'http://dhj.sagepub.com/content/2/2055207616642118.full'), ('D.Zinoviev, \"The Pain of Complexity,\"', 'http://www.mitpressjournals.org/doi/abs/10.1162/LEON_a_01271#.VzOvwHUrKzc'), ('D.Zinoviev, Z.Zhu, and K.Li, \"Building mini-categories in product networks,\"', 'http://link.springer.com/chapter/10.1007/978-3-319-16112-9_18'), ('D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Mitigation of delayed management costs in transaction-oriented systems,\"', 'http://arxiv.org/abs/1409.6771'), ('D.Zinoviev, H.Benbrahim, G.Meszoely, and D.Stefanescu, \"Simulating resilience in transaction-oriented networks,\"', 'http://dl.acm.org/citation.cfm?id=2499974'), ('D.Zinoviev, D.Stefanescu, L.Swenson, and G.Fireman, \"Semantic networks of interests in online NSSI communities,\"', 'http://arxiv.org/abs/1206.5520'), ('D.Zinoviev and S.Llewelyn, \"Co-Evolution of Friendship and Publishing in Online Blogging Social Networks,\"', 'http://arxiv.org/abs/1401.6964'), ('D.Zinoviev, \"Information diffusion in social networks,\"', 'http://dl.acm.org/citation.cfm?id=2208181'), ('D.Zinoviev and V.Duong, \"A game theoretical approach to broadcast  information diffusion in social networks,\"', 'http://dl.acm.org/citation.cfm?id=2048377'), ('D.Zinoviev and V.Duong, \"A game theoretical approach to modeling full-duplex information dissemination,\"', 'http://dl.acm.org/citation.cfm?id=1999462'), ('D.Zinoviev, V.Duong, and H.Zhang, \"A game theoretical approach to modeling information dissemination in social networks,\"', 'http://arxiv.org/abs/1006.5493'), ('D.Zinoviev and V.Duong, \"Toward Understanding Friendship in Online Social Networks,\"', 'http://arxiv.org/abs/0902.4658'), ('D.Zinoviev, \"Topology and Geometry of Online Social Networks,\"', 'http://arxiv.org/abs/0807.3996'), ('Vixi: The Game of Meaning', '/vixi/html5/'), ('Evgenia Cherkasova', 'http://meaningoflife.cherkasova.org/'), ('All Characters from War and Peace by L.Tolstoy', 'v2.jpg'), ('Mapping the Bible: Social Networks in the Holy Book', 'bible-networks.pdf'), ('FIFA World Cup 2014: Who Beat Whom?', 'wc2014.gif'), ('The seed post \"9 American habits I lost when I moved to Germany\" and its 125 \"likes\" and \"shares\" on Facebook', 'facebook_spread.gif'), ('Email', 'mailto:dzinoviev@suffolk.edu'), ('Suffolk University', 'https://www.suffolk.edu/academics/faculty/z/i/dmitry-zinoviev'), ('Google Scholar', 'https://scholar.google.com/citations?hl=en&user=j5GjuIkAAAAJ&sortby=pubdate&view_op=list_works&pagesize=100'), ('LinkedIn', 'https://www.linkedin.com/pub/dmitry-zinoviev/4/a78/27b'), ('Academia.edu', 'https://suffolk.academia.edu/DmitryZinoviev'), ('ResearchGate', 'https://www.researchgate.net/profile/Dmitry_Zinoviev')]\n"
     ]
    }
   ],
   "source": [
    "htmlString = ''' <HTML>\n",
    "  <HEAD><TITLE>My document</TITLE></HEAD>\n",
    "  <BODY>Main text.</BODY></HTML>\n",
    "'''\n",
    "soup = BeautifulSoup(htmlString)\n",
    "print('*soup=>', soup)\n",
    "mystr=soup.get_text()\n",
    "print('*mystr=>', mystr)  # Uchang\n",
    "#---------------------------------------\n",
    "\n",
    "with urlopen(\"http://www.networksciencelab.com/\") as doc: \n",
    "  soup = BeautifulSoup(doc)\n",
    "\n",
    "# print(soup) # Uchang\n",
    "links = [(link.string, link[\"href\"])\n",
    "    for link in soup.find_all(\"a\")\n",
    "    if link.has_attr(\"href\")]\n",
    "print('*links=>', 'links=>', links)\n",
    "#---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "9.4 16.09830908994965\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"Demographic_Statistics-simple.csv\", newline='') as infile:\n",
    "  data = list(csv.reader(infile))\n",
    "#---------------------------------------\n",
    "countParticipantsIndex = data[0].index(\"COUNT PARTICIPANTS\")\n",
    "print(countParticipantsIndex)\n",
    "#---------------------------------------\n",
    "\n",
    "import statistics\n",
    "countParticipants = [int(row[countParticipantsIndex]) for row in data[1:]]\n",
    "print(statistics.mean(countParticipants), statistics.stdev(countParticipants))\n",
    "#---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유사어=> [Synset('cat.n.01'), Synset('guy.n.01'), Synset('cat.n.03'), Synset('kat.n.01'), Synset('cat-o'-nine-tails.n.01'), Synset('caterpillar.n.02'), Synset('big_cat.n.01'), Synset('computerized_tomography.n.01'), Synset('cat.v.01'), Synset('vomit.v.01')]\n",
      "상위어=> [Synset('feline.n.01')]\n",
      "하위어=> [Synset('domestic_cat.n.01'), Synset('wildcat.n.03')]\n",
      "유사도=> 0.04\n",
      "['an informal term for a youth or man', 'informal term for a man']\n",
      "test=>\n",
      "*path-sim=> Synset('cat.n.01') Synset('dog.n.01') 0.2\n",
      "*path-sim=> Synset('cat.n.01') Synset('frump.n.01') 0.07142857142857142\n",
      "*path-sim=> Synset('cat.n.01') Synset('dog.n.03') 0.07692307692307693\n",
      "*path-sim=> Synset('cat.n.01') Synset('cad.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('cat.n.01') Synset('frank.n.02') 0.05263157894736842\n",
      "*path-sim=> Synset('cat.n.01') Synset('pawl.n.01') 0.058823529411764705\n",
      "*path-sim=> Synset('cat.n.01') Synset('andiron.n.01') 0.0625\n",
      "*path-sim=> Synset('cat.n.01') Synset('chase.v.01') None\n",
      "*path-sim=> Synset('guy.n.01') Synset('dog.n.01') 0.125\n",
      "*path-sim=> Synset('guy.n.01') Synset('frump.n.01') 0.125\n",
      "*path-sim=> Synset('guy.n.01') Synset('dog.n.03') 0.2\n",
      "*path-sim=> Synset('guy.n.01') Synset('cad.n.01') 0.14285714285714285\n",
      "*path-sim=> Synset('guy.n.01') Synset('frank.n.02') 0.08333333333333333\n",
      "*path-sim=> Synset('guy.n.01') Synset('pawl.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('guy.n.01') Synset('andiron.n.01') 0.08333333333333333\n",
      "*path-sim=> Synset('guy.n.01') Synset('chase.v.01') None\n",
      "*path-sim=> Synset('cat.n.03') Synset('dog.n.01') 0.125\n",
      "*path-sim=> Synset('cat.n.03') Synset('frump.n.01') 0.125\n",
      "*path-sim=> Synset('cat.n.03') Synset('dog.n.03') 0.14285714285714285\n",
      "*path-sim=> Synset('cat.n.03') Synset('cad.n.01') 0.14285714285714285\n",
      "*path-sim=> Synset('cat.n.03') Synset('frank.n.02') 0.08333333333333333\n",
      "*path-sim=> Synset('cat.n.03') Synset('pawl.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('cat.n.03') Synset('andiron.n.01') 0.08333333333333333\n",
      "*path-sim=> Synset('cat.n.03') Synset('chase.v.01') None\n",
      "*path-sim=> Synset('kat.n.01') Synset('dog.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('kat.n.01') Synset('frump.n.01') 0.1\n",
      "*path-sim=> Synset('kat.n.01') Synset('dog.n.03') 0.1111111111111111\n",
      "*path-sim=> Synset('kat.n.01') Synset('cad.n.01') 0.1111111111111111\n",
      "*path-sim=> Synset('kat.n.01') Synset('frank.n.02') 0.09090909090909091\n",
      "*path-sim=> Synset('kat.n.01') Synset('pawl.n.01') 0.07142857142857142\n",
      "*path-sim=> Synset('kat.n.01') Synset('andiron.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('kat.n.01') Synset('chase.v.01') None\n",
      "*path-sim=> Synset('cat-o'-nine-tails.n.01') Synset('dog.n.01') 0.08333333333333333\n",
      "*path-sim=> Synset('cat-o'-nine-tails.n.01') Synset('frump.n.01') 0.07142857142857142\n",
      "*path-sim=> Synset('cat-o'-nine-tails.n.01') Synset('dog.n.03') 0.07692307692307693\n",
      "*path-sim=> Synset('cat-o'-nine-tails.n.01') Synset('cad.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('cat-o'-nine-tails.n.01') Synset('frank.n.02') 0.06666666666666667\n",
      "*path-sim=> Synset('cat-o'-nine-tails.n.01') Synset('pawl.n.01') 0.14285714285714285\n",
      "*path-sim=> Synset('cat-o'-nine-tails.n.01') Synset('andiron.n.01') 0.16666666666666666\n",
      "*path-sim=> Synset('cat-o'-nine-tails.n.01') Synset('chase.v.01') None\n",
      "*path-sim=> Synset('caterpillar.n.02') Synset('dog.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('caterpillar.n.02') Synset('frump.n.01') 0.06666666666666667\n",
      "*path-sim=> Synset('caterpillar.n.02') Synset('dog.n.03') 0.07142857142857142\n",
      "*path-sim=> Synset('caterpillar.n.02') Synset('cad.n.01') 0.07142857142857142\n",
      "*path-sim=> Synset('caterpillar.n.02') Synset('frank.n.02') 0.0625\n",
      "*path-sim=> Synset('caterpillar.n.02') Synset('pawl.n.01') 0.1\n",
      "*path-sim=> Synset('caterpillar.n.02') Synset('andiron.n.01') 0.1111111111111111\n",
      "*path-sim=> Synset('caterpillar.n.02') Synset('chase.v.01') None\n",
      "*path-sim=> Synset('big_cat.n.01') Synset('dog.n.01') 0.2\n",
      "*path-sim=> Synset('big_cat.n.01') Synset('frump.n.01') 0.07142857142857142\n",
      "*path-sim=> Synset('big_cat.n.01') Synset('dog.n.03') 0.07692307692307693\n",
      "*path-sim=> Synset('big_cat.n.01') Synset('cad.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('big_cat.n.01') Synset('frank.n.02') 0.05263157894736842\n",
      "*path-sim=> Synset('big_cat.n.01') Synset('pawl.n.01') 0.058823529411764705\n",
      "*path-sim=> Synset('big_cat.n.01') Synset('andiron.n.01') 0.0625\n",
      "*path-sim=> Synset('big_cat.n.01') Synset('chase.v.01') None\n",
      "*path-sim=> Synset('computerized_tomography.n.01') Synset('dog.n.01') 0.05263157894736842\n",
      "*path-sim=> Synset('computerized_tomography.n.01') Synset('frump.n.01') 0.05555555555555555\n",
      "*path-sim=> Synset('computerized_tomography.n.01') Synset('dog.n.03') 0.058823529411764705\n",
      "*path-sim=> Synset('computerized_tomography.n.01') Synset('cad.n.01') 0.058823529411764705\n",
      "*path-sim=> Synset('computerized_tomography.n.01') Synset('frank.n.02') 0.05555555555555555\n",
      "*path-sim=> Synset('computerized_tomography.n.01') Synset('pawl.n.01') 0.05\n",
      "*path-sim=> Synset('computerized_tomography.n.01') Synset('andiron.n.01') 0.05263157894736842\n",
      "*path-sim=> Synset('computerized_tomography.n.01') Synset('chase.v.01') None\n",
      "*path-sim=> Synset('cat.v.01') Synset('dog.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('cat.v.01') Synset('frump.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('cat.v.01') Synset('dog.n.03') 0.08333333333333333\n",
      "*path-sim=> Synset('cat.v.01') Synset('cad.n.01') 0.08333333333333333\n",
      "*path-sim=> Synset('cat.v.01') Synset('frank.n.02') 0.08333333333333333\n",
      "*path-sim=> Synset('cat.v.01') Synset('pawl.n.01') 0.07142857142857142\n",
      "*path-sim=> Synset('cat.v.01') Synset('andiron.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('cat.v.01') Synset('chase.v.01') 0.14285714285714285\n",
      "*path-sim=> Synset('vomit.v.01') Synset('dog.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('vomit.v.01') Synset('frump.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('vomit.v.01') Synset('dog.n.03') 0.08333333333333333\n",
      "*path-sim=> Synset('vomit.v.01') Synset('cad.n.01') 0.08333333333333333\n",
      "*path-sim=> Synset('vomit.v.01') Synset('frank.n.02') 0.08333333333333333\n",
      "*path-sim=> Synset('vomit.v.01') Synset('pawl.n.01') 0.07142857142857142\n",
      "*path-sim=> Synset('vomit.v.01') Synset('andiron.n.01') 0.07692307692307693\n",
      "*path-sim=> Synset('vomit.v.01') Synset('chase.v.01') 0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "wn = nltk.corpus.wordnet # 코퍼스 리더(reader)\n",
    "print('유사어=>',wn.synsets(\"cat\"))\n",
    "#---------------------------------------\n",
    "print('상위어=>',wn.synset(\"cat.n.01\").hypernyms())\n",
    "print('하위어=>',wn.synset(\"cat.n.01\").hyponyms())\n",
    "#---------------------------------------\n",
    "x = wn.synset(\"cat.n.01\")\n",
    "y = wn.synset(\"lynx.n.01\")\n",
    "print('유사도=>',x.path_similarity(y))\n",
    "#---------------------------------------\n",
    "# synset들이 서로 관련 있는지 확인한다.\n",
    "print([simxy.definition() for simxy in max(\n",
    "  (x.path_similarity(y), x, y)\n",
    "  for x in wn.synsets('cat')\n",
    "  for y in wn.synsets('dog')\n",
    "  if x.path_similarity(y))[1:]])\n",
    "#---------------------------------------\n",
    "print('test=>')\n",
    "for x in wn.synsets('cat'):\n",
    "    for y in wn.synsets('dog'):\n",
    "        print('*path-sim=>', x, y, x.path_similarity(y))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 2, 2, 2, 3, 3, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test code\n",
    "[a for a in [1,2,3]\n",
    "  for x in ['c','a','b']\n",
    "  for y in ['a','b','c']\n",
    "  if x==y[0:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['}', 'Help', '!', ':)))', ':[', '.....', ':', 'D', '{']\n",
      "wonder\n",
      "wond\n",
      "wonderful\n",
      "[('beautiful', 'JJ'), ('world', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# 자연어처리 https://wikidocs.net/book/2155\n",
    "from nltk.tokenize import WordPunctTokenizer \n",
    "word_punct = WordPunctTokenizer()\n",
    "text = \"}Help! :))) :[ ..... :D{\" \n",
    "print(word_punct.tokenize(text))\n",
    "#---------------------------------------\n",
    "nltk.word_tokenize(text)\n",
    "# 접미사제거, https://wikidocs.net/21707\n",
    "pstemmer = nltk.PorterStemmer() \n",
    "print(pstemmer.stem(\"wonderful\"))\n",
    "lstemmer = nltk.LancasterStemmer()\n",
    "print(lstemmer.stem(\"wonderful\"))\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"wonderful\"))\n",
    "print(nltk.pos_tag([\"beautiful\", \"world\"]))\n",
    "#---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New', 'Document', 'document.location', '=', \"'menu.jsp\", \"'\", ';']\n",
      "['new', 'document', 'document.location', '=', \"'menu.jsp\", \"'\", ';']\n",
      "stemming=> ['new', 'docu']\n",
      "Counter({'new': 1, 'docu': 1})\n",
      "[('new', 1), ('docu', 1)]\n",
      "end...\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import LancasterStemmer\n",
    "# 형태소 분류기를 생성한다.\n",
    "ls = nltk.LancasterStemmer()\n",
    "# 파일을 읽고 soup을 만든다. \n",
    "with open(\"index.html\") as infile:\n",
    "  soup = BeautifulSoup(infile)\n",
    "\n",
    "words = nltk.word_tokenize(soup.text) # 텍스트를 추출하고 토큰화한다.\n",
    "print(words) # Uchang\n",
    "words = [w.lower() for w in words] # 단어를 소문자로 변환한다.\n",
    "print(words) # Uchang\n",
    "# 불용어를 제거하고 단어의 형태소를 추출한다.\n",
    "words = [ls.stem(w) for w in words if w not in stopwords.words(\"english\") and w.isalnum()]\n",
    "print('stemming=>',words) # Uchang \n",
    "freqs = Counter(words) # 가장 빈번하게 등장한 단어 10개를 추출한다.  \n",
    "print(freqs)\n",
    "print(freqs.most_common(10))\n",
    "print('end...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
